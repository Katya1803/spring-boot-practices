input {
  # TCP input for direct log streaming from app
  tcp {
    port => 5000  # Internal port
    codec => json_lines
    tags => ["tcp-json"]
  }

  # Beats input (for Filebeat) - Internal port
  beats {
    port => 5044  # Internal port (container-to-container)
    tags => ["filebeat"]
  }

  # File input (read directly from log files)
  file {
    path => "/logs/application*.log"
    start_position => "beginning"
    sincedb_path => "/dev/null"
    codec => json
    tags => ["file-json", "application"]
  }

  # SQL logs
  file {
    path => "/logs/sql*.log"
    start_position => "beginning"
    sincedb_path => "/dev/null"
    codec => json
    tags => ["file-json", "sql"]
  }

  # Error logs
  file {
    path => "/logs/error*.log"
    start_position => "beginning"
    sincedb_path => "/dev/null"
    codec => json
    tags => ["file-json", "error"]
  }
}

filter {
  # Parse JSON if not already parsed
  if "json" not in [tags] and [message] =~ /^\{/ {
    json {
      source => "message"
      remove_field => ["message"]
    }
  }

  # Clean up logger names - shorten them
  if [logger_name] {
    mutate {
      gsub => [
        "logger_name", "com\.katya\.app\.", "",
        "logger_name", "org\.springframework\.", "spring.",
        "logger_name", "org\.apache\.", "apache."
      ]
    }
  }

  # Add log type based on tags or path
  if "sql" in [tags] {
    mutate {
      add_field => { "log_type" => "sql" }
    }
  } else if "error" in [tags] or [level] == "ERROR" {
    mutate {
      add_field => { "log_type" => "error" }
    }
  } else if "application" in [tags] {
    mutate {
      add_field => { "log_type" => "application" }
    }
  }

  # Add custom fields
  mutate {
    add_field => {
      "[@metadata][index_prefix]" => "cms-logs"
      "environment" => "development"
    }
  }

  # Parse timestamp if exists
  if [@timestamp] {
    date {
      match => ["@timestamp", "ISO8601", "yyyy-MM-dd'T'HH:mm:ss.SSSZ", "yyyy-MM-dd HH:mm:ss.SSS"]
      target => "@timestamp"
    }
  }

  # Ensure log level is uppercase
  if [level] {
    mutate {
      uppercase => ["level"]
    }
  }

  # Clean up stack traces
  if [stack_trace] {
    mutate {
      gsub => [
        "stack_trace", "\t", "  ",
        "stack_trace", "\\n", " | "
      ]
    }
  }

  # Extract SQL query info if present
  if [log_type] == "sql" and [message] {
    grok {
      match => {
        "message" => "^(==>  Preparing:|<==      Total:|<==    Updates:)?[\s]*%{WORD:sql_type}"
      }
      tag_on_failure => []
    }
  }

  # Remove unnecessary fields
  mutate {
    remove_field => ["beat", "prospector", "input", "source", "offset"]
  }
}

output {
  if [log_type] == "sql" {
    elasticsearch {
      hosts => ["${ELASTICSEARCH_HOSTS:http://cms-elasticsearch:9200}"]
      index => "cms-sql-%{+YYYY.MM.dd}"
    }
  } else if [log_type] == "error" {
    elasticsearch {
      hosts => ["${ELASTICSEARCH_HOSTS:http://cms-elasticsearch:9200}"]
      index => "cms-error-%{+YYYY.MM.dd}"
    }
  } else {
    elasticsearch {
      hosts => ["${ELASTICSEARCH_HOSTS:http://cms-elasticsearch:9200}"]
      index => "cms-logs-%{+YYYY.MM.dd}"
    }
  }

  stdout {
    codec => rubydebug {
      metadata => false
    }
  }
}